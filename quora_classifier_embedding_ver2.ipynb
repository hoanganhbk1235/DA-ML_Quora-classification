{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "quora_classifier_ver2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8B47A0dcDgQB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBfCNQ3ZE7pn",
        "colab_type": "text"
      },
      "source": [
        "**tài liệu tham khảo**\n",
        "+ https://forum.machinelearningcoban.com/t/vnlp-core-3-bai-toan-phan-loai-van-ban-phan-tich-cam-xuc-cua-binh-luan-text-classification/2371\n",
        "+ https://forum.machinelearningcoban.com/t/vnlp-core-1-bai-toan-tach-tu-tieng-viet-tokenization-word-segmentation/2002\n",
        "+ https://forum.machinelearningcoban.com/t/vnlp-core-2-thuc-hanh-training-va-su-dung-bieu-dien-tu-trong-khong-gian-word-embedding/2101?fbclid=IwAR2n3avtbLPavpxl9Mb6yBiV1xgR-udAKOIjRoo9v2tonILNFgkfZ6-84yk\n",
        "\n",
        "+ f1_score : https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7Dx8avmE7ma",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0TziIgp4F-p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yd2X7cNN534y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pprint\n",
        "import tensorflow as tf\n",
        "\n",
        "if 'COLAB_TPU_ADDR' not in os.environ:\n",
        "  print('ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!')\n",
        "else:\n",
        "  tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "  print ('TPU address is', tpu_address)\n",
        "\n",
        "  with tf.Session(tpu_address) as session:\n",
        "    devices = session.list_devices()\n",
        "    \n",
        "  print('TPU devices:')\n",
        "  pprint.pprint(devices)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5VCJOsRFugB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "from scipy.sparse import csr_matrix\n",
        "from scipy.sparse import coo_matrix, hstack, vstack\n",
        "\n",
        "from sklearn import model_selection, naive_bayes, svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, Dropout\n",
        "from keras.constraints import max_norm\n",
        "\n",
        "\n",
        "import math\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras import optimizers\n",
        "from sklearn.metrics import classification_report,confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHds8EcIMjEc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import SGD"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_U846VYCDrXA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# x_train = pd.ExcelFile('/content/drive/My Drive/Colab Notebooks/project_final/quora-insincere-questions-classification/quora_train.xlsx')\n",
        "# quora_train = x_train.parse('Sheet1')\n",
        "# x_test = pd.ExcelFile('/content/drive/My Drive/Colab Notebooks/project_final/quora-insincere-questions-classification/quora_val.xlsx')\n",
        "# quora_test = x_test.parse('Sheet1')\n",
        "\n",
        "x_train = pd.ExcelFile('/content/drive/My Drive/quora-insincere-questions-classification/quora_train.xlsx')\n",
        "quora_train = x_train.parse('Sheet1')\n",
        "x_test = pd.ExcelFile('/content/drive/My Drive/quora-insincere-questions-classification/quora_val.xlsx')\n",
        "quora_test = x_test.parse('Sheet1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaxBmyvVFsa9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(quora_train.shape)\n",
        "print(quora_test.shape)\n",
        "quora_train.head(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5PpSn6n8nHU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "quora_test.head(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLgoIspnGKti",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "quora_train = quora_train.replace(np.nan, '')\n",
        "quora_test = quora_test.replace(np.nan, '')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLs7yrhuGKrC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence_train = quora_train.text_norm1.values\n",
        "sentence_test = quora_test['text_norm1'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBpzssxJGKmR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = quora_train.target.values\n",
        "y_test = quora_test.target.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTNBjc-mLWyX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def count_words(statement):\n",
        "  statement = statement.replace('  ', ' ')\n",
        "  return len(statement.split())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6E1yWHuLLB1X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "quora_train['num_words_2'] = quora_train.text_norm1.apply(count_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_vTqk8ELwzR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "quora_train.num_words_2.value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcFFt4mHKyCn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "quora_train.num_words_2.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L17hGfUsK-dP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# str_sentence_train = \" \".join(sentence_train).replace('  ', ' ')\n",
        "# ls_word = list(set(str_sentence_train.split()))\n",
        "# len(ls_word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1mE2NBuHBP7",
        "colab_type": "text"
      },
      "source": [
        "# tokenizer the sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOlaAM6DGKjS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embeddings_index = {}\n",
        "\n",
        "# f = open('/content/drive/My Drive/Colab Notebooks/project_final/quora-insincere-questions-classification/embeddings/glove.840B.300d/glove.840B.300d.txt')\n",
        "f = open('/content/drive/My Drive/quora-insincere-questions-classification/embeddings/glove.840B.300d/glove.840B.300d.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75149mf9GKgb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for line in tqdm(f):\n",
        "    values = line.split(\" \")\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9b87g-CuGKYa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(embeddings_index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFNy3d3y9zh8",
        "colab_type": "text"
      },
      "source": [
        "# create embedding matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3lz4rr4NHwr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def the_norm_text(text, maxlen = 30):       \n",
        "  # add empty string into text\n",
        "  ls_seq =  text.split() + ['0']*( maxlen - len(text.split()))\n",
        "  return \" \".join(ls_seq)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLTUcrrjNcdb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def text_to_vector(text):\n",
        "  '''\n",
        "  input:(str) text\n",
        "  output:(list) array( 1, 300*30) have 1 vecter size (, 300*30)\n",
        "          represent a text is a vector to have \n",
        "  '''\n",
        "  \n",
        "  # in this problem\n",
        "  # vì phần lớn text_norm1 có dộ dài nhỏ hơn 30, 1 vài câu là độ dài lớn hơn 30\n",
        "  # choose maxlen = 30 , because we remove excess character\n",
        "  # if senquence have not enough 30 words\n",
        "  \n",
        "  if len(text.split()) <30:\n",
        "    text = the_norm_text(text, maxlen= 30)\n",
        "  \n",
        "  ls_text = text.split()[:30]\n",
        "#   print(ls_text)\n",
        "#   return len(ls_text)\n",
        "  # vector visualize sequence information\n",
        "  vec_sequence = []\n",
        "  \n",
        "  for word in ls_text:\n",
        "    \n",
        "    # tạo vector zeros (1,300)\n",
        "    empyt_emb = np.zeros((1, 300))\n",
        "    \n",
        "    if word != '0':\n",
        "      # vector visualize a word (1x300)\n",
        "      vec_word = embeddings_index.get(word, empyt_emb)\n",
        "    else:\n",
        "      vec_word =  empyt_emb\n",
        "    # reshape columns vector to row vector\n",
        "    vec_word = vec_word.reshape((1, -1))\n",
        "    \n",
        "    vec_sequence += list(vec_word)\n",
        "    \n",
        "  # convert 2d array (30, 300) to 1d array (1, 9000)\n",
        "  #return csr_matrix(np.reshape(np.array(vec_sequence), (1,np.product(np.array(vec_sequence).shape))))\n",
        "  return np.reshape(np.array(vec_sequence), (1,np.product(np.array(vec_sequence).shape)))\n",
        "  #return np.array(vec_sequence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0-5jUZINggo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data providers\n",
        "# số điểm dữ liệu trong 1 cụm\n",
        "batch_size = 100\n",
        "\n",
        "def batch_gen(train_df):\n",
        "  # thực hiện chia tập dữ liệu thành n_batches cụm, mỗi cụm có batch_size phần tử \n",
        "  n_batches = math.ceil(len(train_df) / batch_size)\n",
        "  while True: \n",
        "    # xáo trộn dữ liệu \n",
        "    train_df = train_df.sample(frac=1.)  # Shuffle the data.\n",
        "     \n",
        "    for i in range(n_batches):\n",
        "      # thực hiện feature engineering cho cụm dữ liệu thứ i\n",
        "      # tập dữ liệu của cta có các cột: pid, question_text, target, text_norm1, num_word_2\n",
        "      # ta lấy list text ở côt text_norm , số lượng là batch_size = 128 điểm dữ liệu\n",
        "      # vd: i=0 : train_df.iloc[i*batch_size:(i+1)*batch_size, 3] =>train_df.iloc[0*128:(0+1)*128, 3] \n",
        "      # vd: i=1 : train_df.iloc[i*batch_size:(i+1)*batch_size, 3] =>train_df.iloc[1*128:(1+1)*128, 3] \n",
        "      texts = train_df.iloc[i*batch_size:(i+1)*batch_size, 3]\n",
        "      # với list text lấy được buowcs trên ta thực hiện convert text to vector cho từng dòng text và lưu vào 1 mảng\n",
        "      for text in texts:\n",
        "        assert text_to_vector(text).shape == (1, 9000), text\n",
        "      text_arr = np.array([text_to_vector(text) for text in texts])\n",
        "      \n",
        "      # ta lấy nhãn tương ứng cho từng cụm dữ liệu khi trả về (y_train)\n",
        "      # vd i= 0 : np.array(train_df[\"target\"][i*batch_size:(i+1)*batch_size]) = np.array(train_df[\"target\"][0*128:(0+1)*128])\n",
        "      \n",
        "      # yield là phương thức trả về nhiều lần của python\n",
        "      # return trả về 1 lần\n",
        "      #print(text_arr.shape)\n",
        "      # reshape araay (128, 1, 9000) to (128, 9000)\n",
        "      if i < n_batches - 1:\n",
        "        text_arr =  text_arr.reshape((batch_size, -1))\n",
        "      else:\n",
        "        text_arr =  text_arr.reshape((text_arr.shape[0], -1))\n",
        "      #assert text_arr.shape == (128, 9000)\n",
        "      yield text_arr, np.array(train_df[\"target\"][i*batch_size:(i+1)*batch_size])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtU6CrDh-YYz",
        "colab_type": "text"
      },
      "source": [
        "**split train, validation set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qq7JE6DsBGCy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "quora_train, quora_val = train_test_split(quora_train, test_size=0.06)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuJODlrXAMwz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence_val = quora_val.text_norm1.values\n",
        "y_val = quora_val.target.values\n",
        "print(len(sentence_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7vxiap0Ah_u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_vects = np.array([text_to_vector(x_val) for x_val in sentence_val])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9c6OJAr-mrc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_vects.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByRG469j-mo1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_vects.shape[2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LofD5CcW-mmW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_vects = val_vects.reshape(val_vects.shape[0], val_vects.shape[2])\n",
        "val_vects.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJYSpvSN-ruE",
        "colab_type": "text"
      },
      "source": [
        "# training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gW4zkrgc-mjc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # create neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(64, input_dim=9000, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "# reduce overfitting \n",
        "model.add(Dense(32, kernel_constraint=max_norm(3), bias_constraint=max_norm(3)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# setup optimizer para for model, use sgd\n",
        "opt = SGD(lr=0.001,  decay=0.01)\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# bien save model\n",
        "check_point = ModelCheckpoint('/content/drive/My Drive/quora-insincere-questions-classification/neural_network_emb_ver_01.h5', monitor='val_loss', save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTqIz6OQ_1kF",
        "colab_type": "text"
      },
      "source": [
        "**steps_per_epoch**\n",
        "+ Integer. Total number of steps (batches of samples) to yield from generator before declaring one epoch finished and starting the next epoch. It should typically be equal to ceil(num_samples / batch_size) Optional for Sequence: if unspecified, will use the len(generator) as a number of steps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0RyKNpGY5fT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def input_noQuit(prompt):\n",
        "    while True: #broken by return\n",
        "        try:\n",
        "            return input(prompt)\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"you are not allowed to quit right now\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbOQIPB2-mg0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train the model, iterating on the data in batches of 32 samples\n",
        "mg = batch_gen(quora_train)\n",
        "input_noQuit(model.fit_generator(mg, epochs=20, steps_per_epoch=(math.ceil(len(quora_train) / batch_size)),validation_data=(val_vects, y_val),verbose=1, callbacks= [ check_point]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68DPSg52-meM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_preds = np.array([model.predict(text_to_vector(x)) for x in quora_test['text_norm1'] ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sTd0kCC-mbj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = all_preds.reshape(all_preds.shape[0],)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCFeygVv-mY4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# choose with y_prod >= 0.29 => label = 1, y_prod < 0.29 => label = 0\n",
        "y_class = np.squeeze(a >= 0.5).astype('int')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDQMzVfX-mV-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "array_2 = y_class.reshape(1, -1)\n",
        "print(array_2.shape)\n",
        "array_2 = array_2[0]\n",
        "print(array_2.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRFwvhIR-mTF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(classification_report(y_pred = array_2, y_true= y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFzWr724hir0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}