{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "LvjmI9eq0813"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "twZQvKc86BHa"
   },
   "source": [
    "# reference:\n",
    "\n",
    "\n",
    "1. softmax \n",
    "    + https://keras.io/getting-started/sequential-model-guide/\n",
    "\n",
    "2. neural network\n",
    "\n",
    "    + https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/\n",
    "    + https://nttuan8.com/bai-3-neural-network/\n",
    "    + https://nttuan8.com/bai-4-backpropagation/\n",
    "\n",
    "3. bag of word\n",
    "    + https://scikit-learn.org/stable/modules/feature_extraction.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "5obVXRPt5_Ss"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "0NnfczDr3LBb"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "vbfGBkml3ayf"
   },
   "outputs": [],
   "source": [
    "x_train = pd.ExcelFile('...input/quora-insincere-questions-classification/quora_train.xlsx')\n",
    "quora_train = x_train.parse('Sheet1')\n",
    "x_val = pd.ExcelFile('...input/quora-insincere-questions-classification/quora_val.xlsx')\n",
    "quora_val = x_val.parse('Sheet1')\n",
    "# x_test = pd.ExcelFile('/content/drive/My Drive/Colab Notebooks/project_final/quora-insincere-questions-classification/quora_test.xlsx')\n",
    "# quora_test = x_test.parse('Sheet1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "WfBneRD-EJaa"
   },
   "outputs": [],
   "source": [
    "quora_test = pd.read_csv('...input/quora-insincere-questions-classification/quora_test1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "UzB5H3ht4hMp"
   },
   "outputs": [],
   "source": [
    "print(quora_train.shape)\n",
    "print(quora_val.shape)\n",
    "print(quora_test.shape)\n",
    "quora_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "jYWzGA1p5-0N"
   },
   "outputs": [],
   "source": [
    "quora_train = quora_train.replace(np.nan, '')\n",
    "quora_val = quora_val.replace(np.nan, '')\n",
    "quora_test = quora_test.replace(np.nan, '')\n",
    "print(quora_train.shape)\n",
    "print(quora_val.shape)\n",
    "print(quora_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "GF4FZxWG48Ou"
   },
   "outputs": [],
   "source": [
    "quora_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "i-TEvV0I48H1"
   },
   "outputs": [],
   "source": [
    "sentence_train = list(quora_train.text_norm1)\n",
    "sentence_val = list(quora_val.text_norm1)\n",
    "sentence_test = list(quora_test.text_norm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "6u3rz-FmsjAA"
   },
   "outputs": [],
   "source": [
    "quora_train.target = quora_train.target.astype('int')\n",
    "quora_val.target = quora_val.target.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Ko_wBgeftApA"
   },
   "outputs": [],
   "source": [
    "quora_train.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "F_isnFANtEjO"
   },
   "outputs": [],
   "source": [
    "quora_val.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "b-Avwc4A48BG"
   },
   "outputs": [],
   "source": [
    "y_train = quora_train.target.values\n",
    "y_val = quora_val.target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "BVTDb5GqtLjG"
   },
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "LvGqdG7zQb0h"
   },
   "outputs": [],
   "source": [
    "del quora_train\n",
    "del quora_val\n",
    "del quora_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "bBFGA3vMQbwT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Vch_C3L5azd"
   },
   "source": [
    "# 1. Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lb0BV0g-5P0R"
   },
   "source": [
    "#1.1 Bag of word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "ZglPTDW-476E"
   },
   "outputs": [],
   "source": [
    "# create feature vector with Countvectorize by sklearn library\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "yAKJrJq04710"
   },
   "outputs": [],
   "source": [
    "vectorizer_bow = CountVectorizer(min_df=0, lowercase=False)\n",
    "vectorizer_bow.fit(sentence_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "lt9UxgYo47yl"
   },
   "outputs": [],
   "source": [
    "X_train_bow = vectorizer_bow.transform(sentence_train)\n",
    "X_val_bow = vectorizer_bow.transform(sentence_val)\n",
    "X_test_bow = vectorizer_bow.transform(sentence_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "xd-ojoTaOnIh"
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('/content/drive/My Drive/Colab Notebooks/project_final/quora-insincere-questions-classification/train_bow_matrix.pkl', 'wb') as f:\n",
    "#   pickle.dump(X_train_bow, f)\n",
    "  \n",
    "# with open('/content/drive/My Drive/Colab Notebooks/project_final/quora-insincere-questions-classification/val_test_bow_matrix.pkl', 'wb') as f:\n",
    "#   pickle.dump(X_val_bow, f)\n",
    "\n",
    "# with open('/content/drive/My Drive/Colab Notebooks/project_final/quora-insincere-questions-classification/test_bow_matrix.pkl', 'wb') as f:\n",
    "#   pickle.dump(X_test_bow, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "_eCxJt2bPh6M"
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('/content/drive/My Drive/quora-insincere-questions-classification/train_bow_matrix.pkl', 'rb') as f:\n",
    "#   X_train_bow = pickle.load(f)\n",
    "  \n",
    "# with open('/content/drive/My Drive/quora-insincere-questions-classification/val_test_bow_matrix.pkl', 'rb') as f:\n",
    "#   X_val_bow = pickle.load(f)\n",
    "  \n",
    "# with open('/content/drive/My Drive/quora-insincere-questions-classification/test_bow_matrix.pkl', 'rb') as f:\n",
    "#   X_test_bow = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wj_I942m-Yz_"
   },
   "source": [
    "Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "YtbzOEX6-gI7"
   },
   "outputs": [],
   "source": [
    "# # activation function (sigmoid)\n",
    "# def sigmoid(x):\n",
    "#     return (1/(1 + np.exp(-x)))\n",
    "# # derivative of activation function (sigmoid)\n",
    "# def sigmoid_derivative(x):\n",
    "#     return x*(1-x)\n",
    "\n",
    "# class NeuralNetwork:\n",
    "#     def __init__(self, layers, alpha = 0.1):\n",
    "#         '''\n",
    "#         input:\n",
    "#         + layers (list) [n1, n2, n3, ..., n_output]\n",
    "#             the first layer (input layer) contain n1 neurons (input data demension)\n",
    "#             the second layer contain n2 neurons\n",
    "#             the third layer contain n3 neurons\n",
    "#             the last layers (output layer) contain n_ouput neurons\n",
    "#         + alpha (float)\n",
    "\n",
    "#         create\n",
    "#         + layers\n",
    "#         + W matrix contain the weight matrix between the layers\n",
    "#         + b matrix contain the bias vector\n",
    "#         + alpha\n",
    "#         '''\n",
    "#         self.layers = layers\n",
    "#         # learning rate\n",
    "#         self.alpha = alpha\n",
    "#         # the parameters matrix W, b\n",
    "#         self.W = []\n",
    "#         self.b = []\n",
    "#         # create the parameters for the each layer\n",
    "#         for  i in range(0, len(layers) - 1):\n",
    "#             # create matrix w , that is used connecting layer i and layer i+1. \n",
    "#             #the size is (the neurons number of layer i) x (the neurons number of layer i+1)\n",
    "#             w_ = np.random.rand(layers[i], layers[i+1])\n",
    "#             # create vector b for the layer i+1\n",
    "#             # the elements is the neurons number of layer i+1\n",
    "#             b_ = np.zeros((layers[i+1], 1))\n",
    "#             self.W.append(w_)\n",
    "#             self.b.append(b_)\n",
    "#     # description neural model\n",
    "#     def __repr__(self):\n",
    "#         return \"Neural network [{}]\".format(\"-\".join(str(l) for l in self.layers))\n",
    "    \n",
    "#     # train model with data\n",
    "#     def fit_partial(self, x, y):\n",
    "#         A = [x]\n",
    "        \n",
    "#         # feedforward\n",
    "#         out = A[-1]\n",
    "#         for i in range(0, len(self.layers)-1):\n",
    "#             out = sigmoid(np.dot(out, self.W[i]) + (self.b[i].T))\n",
    "#             A.append(out)\n",
    "            \n",
    "#         # backpropagation\n",
    "#         y = y.reshape(-1, 1)\n",
    "#             # init compute derivative of loss function follow y_preditc (A): \n",
    "#             # dL/d(y_predict)\n",
    "#         dA = [-(y/A[-1] - (1-y)/(1-A[-1]))]\n",
    "#         dW = []\n",
    "#         db = []\n",
    "#             # in the step backpropagation\n",
    "#             # we find W, b follow the result predict from output layer back to input layer\n",
    "#         for i in reversed(range(0, len(self.layers)- 1)):\n",
    "#             # dJ/d(W^l) = (A^{l-1}).T * (Y_predict - Y)\n",
    "#             dw_ = np.dot((A[i]).T, dA[-1]*sigmoid_derivative(A[i+1]))\n",
    "#             # dJ/d(b^l) = (sum(Y_predict - Y)).T\n",
    "#             db_ = (np.sum(dA[-1]*sigmoid_derivative(A[i+1]), 0)).reshape(-1, 1)\n",
    "#             # dJ/d(A^{l-1}) = (Y_predict - Y)*(W^l).T\n",
    "#             dA_ = np.dot(dA[-1]*sigmoid_derivative(A[i+1]), self.W[i].T)\n",
    "#             dW.append(dw_)\n",
    "#             db.append(db_)\n",
    "#             dA.append(dA_)\n",
    "#         # reverse dW, db\n",
    "#         dW = dW[::-1]\n",
    "#         db = db[::-1]\n",
    "\n",
    "#         # Gradient descent\n",
    "#         for i in range(0, len(self.layers)-1):\n",
    "#             self.W[i] = self.W[i] - self.alpha * dW[i]\n",
    "#             self.b[i] = self.b[i] - self.alpha * db[i]\n",
    "\n",
    "#     def fit(self, X, y, X_val, y_val, epochs=20, verbose=10):\n",
    "#         for epoch in range(0, epochs):\n",
    "#             self.fit_partial(X, y)\n",
    "#             if epoch % verbose == 0:\n",
    "#                 loss = self.calculate_loss(X, y)\n",
    "#                 loss_val = self.calculate_loss(X_val, y_val)\n",
    "#                 print(\"Epoch {}, loss {}, loss_val {}\".format(epoch, loss, loss_val))\n",
    "\n",
    "#     # Dự đoán\n",
    "#     def predict(self, X):\n",
    "#         for i in range(0, len(self.layers) - 1):\n",
    "#             X = sigmoid(np.dot(X, self.W[i]) + (self.b[i].T))\n",
    "#         return X\n",
    "\n",
    "#     # Tính loss function\n",
    "#     def calculate_loss(self, X, y):\n",
    "#         y_predict = self.predict(X)\n",
    "#         #return np.sum((y_predict-y)**2)/2\n",
    "#         return -(np.sum(y*np.log(y_predict) + (1-y)*np.log(1-y_predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "NcRs-KfB-9b9"
   },
   "outputs": [],
   "source": [
    "# p = NeuralNetwork([X_train.shape[1], 134, 1])\n",
    "# p.fit(X_train_bow, y_train, X_val_bow, y_val, 20, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "eFWcrYh4F-zv"
   },
   "outputs": [],
   "source": [
    "# # create neural network model\n",
    "# odel = Sequential()\n",
    "# model.add(Dense(64, input_dim=X_train_bow.shape[1], activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(64, activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# model.compile(loss='binary_crossentropy',\n",
    "#               optimizer='rmsprop',\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# model.fit(X_train_bow, y_train,\n",
    "#           epochs=20,\n",
    "#           batch_size=128)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B3c51yT1NTmN"
   },
   "source": [
    "# classifier with softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "_msWtX4LGlv-"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import optimizers\n",
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "iNgNIRf_vaXl"
   },
   "outputs": [],
   "source": [
    "# For a single-input model with 2 classes (binary classification):\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(70, activation='relu', input_dim=X_train_bow.shape[1]))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# bien save model\n",
    "check_point = ModelCheckpoint('...input/quora-insincere-questions-classification/softmax_bow_ver_02.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "class_weight = {0:1, 1:15}\n",
    "# Train the model, iterating on the data in batches of 100 samples\n",
    "model.fit(X_train_bow, y_train, epochs=10,validation_split=0.1, verbose=1, callbacks= [ check_point], batch_size=100, class_weight= class_weight)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "RLydmcBhYG5q"
   },
   "outputs": [],
   "source": [
    "y_prod = model.predict_podba(X_val_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "UKlVoYU6pSFm"
   },
   "outputs": [],
   "source": [
    "y_prod[y_prod >= 0.23].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "m1zFpPLto5KV"
   },
   "outputs": [],
   "source": [
    "# choose with y_prod >= 0.23 => label = 1, y_prod < 0.23 => label = 0\n",
    "y_class = np.squezze(y_prod >= 0.23).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "xpKqBEPQo5HX"
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_pred = y_class, y_true= y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "VnsDUlpDo5EO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "iwMLYjry5A_p"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "kU3X-QJu5A85"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "8Vch_C3L5azd"
   ],
   "name": "quora_classifier_ver1.ipynb",
   "private_outputs": true,
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
